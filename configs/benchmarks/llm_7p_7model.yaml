game_name: "llm_7p_7model"
num_players: 7

roles:
  - role: werewolf
    count: 2
  - role: seer
    count: 1
  - role: doctor
    count: 1
  - role: villager
    count: 3

default_model:
  api_base: "http://localhost:11434/v1"
  api_key: "ollama"
  model: "llama3.2:3b"
  reasoning_temperature: 0.7
  action_temperature: 0.3
  timeout: 120.0
  max_tokens: 8192
  context_length: 65536

players:
  - name: Alice
    model:
      api_base: "http://localhost:11434/v1"
      api_key: "ollama"
      model: "gpt-oss:20b"
      reasoning_temperature: 0.7
      action_temperature: 0.3
      timeout: 120.0
      max_tokens: 8192
      context_length: 65536
  - name: Bob
    model:
      api_base: "http://localhost:11434/v1"
      api_key: "ollama"
      model: "llama3.2:3b"
      reasoning_temperature: 0.7
      action_temperature: 0.3
      timeout: 120.0
      max_tokens: 8192
      context_length: 65536
  - name: Charlie
    model:
      api_base: "http://localhost:11434/v1"
      api_key: "ollama"
      model: "llama3.1:8b"
      reasoning_temperature: 0.7
      action_temperature: 0.3
      timeout: 120.0
      max_tokens: 8192
      context_length: 65536
  - name: Diana
    model:
      api_base: "http://localhost:11434/v1"
      api_key: "ollama"
      model: "cogito:8b"
      reasoning_temperature: 0.7
      action_temperature: 0.3
      timeout: 120.0
      max_tokens: 8192
      context_length: 65536
  - name: Eve
    model:
      api_base: "http://localhost:11434/v1"
      api_key: "ollama"
      model: "qwen3:30b-a3b"
      reasoning_temperature: 0.7
      action_temperature: 0.3
      timeout: 120.0
      max_tokens: 8192
      context_length: 32768
  - name: Frank
    model:
      api_base: "http://localhost:11434/v1"
      api_key: "ollama"
      model: "qwq:32b-q4_K_M"
      reasoning_temperature: 0.7
      action_temperature: 0.3
      timeout: 180.0
      max_tokens: 8192
      context_length: 32768
  - name: Grace
    model:
      api_base: "http://localhost:11434/v1"
      api_key: "ollama"
      model: "qwen3:8b"
      reasoning_temperature: 0.7
      action_temperature: 0.3
      timeout: 120.0
      max_tokens: 8192
      context_length: 32768

voting:
  method: "plurality"
  reveal_votes: true
  tie_breaker: "random"

communication:
  allow_wolf_chat: true
  allow_dms: false
  discussion_rounds: 1
  max_speech_length: 300

max_days: 5
